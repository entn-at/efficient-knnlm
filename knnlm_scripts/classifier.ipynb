{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sequential(*[nn.Linear(1,2), nn.ReLU()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifer(nn.Module):\n",
    "    def __init__(self, nfeature, hidden_units=32, nlayers=3, dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        models = [nn.Linear(nfeature, hidden_units), nn.Dropout(p=dropout)]\n",
    "        for _ in range(nlayers-1):\n",
    "            models.extend([nn.Linear(hidden_units, hidden_units)])\n",
    "            \n",
    "        models.append(nn.Linear(hidden_units, 2))\n",
    "        \n",
    "        self.model = nn.Sequential(*models)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        \n",
    "        return self.model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenFeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return{\n",
    "            \"id\": index,\n",
    "            \"feature\": self.src[index],\n",
    "            \"label\": self.tgt[index],\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def collater(self, samples):\n",
    "        def merge(key, dtype=torch.float32):\n",
    "            return torch.tensor([s[key] for s in samples], \n",
    "                                dtype=dtype,\n",
    "                                device=self.device)\n",
    "        \n",
    "        batch = {\n",
    "            'id': merge('id'),\n",
    "            'feature': merge('feature'),\n",
    "            'label': merge('label', dtype=torch.long),\n",
    "        }\n",
    "        return batch\n",
    "    \n",
    "    def get_nfeature(self):\n",
    "        return len(self.src[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_ngram_freq(file, ngram=4):\n",
    "    res = Counter()\n",
    "    prev = ['</s>']\n",
    "    with open(file) as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i % 100000 == 0:\n",
    "                print(f'procesed {i} lines')\n",
    "            for tok in line.strip().split():\n",
    "                prev = prev[-ngram:]\n",
    "                for j in range(1, ngram+1):\n",
    "                    res[' '.join(prev[-j:])] += 1  \n",
    "                prev.append(tok)\n",
    "                \n",
    "            prev.append('</s>')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(hypos, freq_cnt, ngram=4):\n",
    "    features = []\n",
    "    labels = []\n",
    "    prev = ['</s>']\n",
    "    for hypo in hypos:\n",
    "        for i in range(len(hypo['string'])):\n",
    "            local_f = []\n",
    "            # confidence-related features\n",
    "            local_f.extend([hypo['lm_entropy'][i], np.exp(hypo['lm_max'][i])])\n",
    "            labels.append(int((hypo['positional_scores'][i] - hypo['lm_scores'][i]) > 0.01))\n",
    "            # frequency-related featuress\n",
    "            tok = hypo['string'][i]\n",
    "            prev = prev[-ngram:]\n",
    "            for j in range(1, ngram+1):\n",
    "                local_f.append(freq_cnt[' '.join(prev[-j:])])\n",
    "            prev.append(tok)\n",
    "            \n",
    "            features.append(local_f)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypos = []\n",
    "with open('../analysis_new.jsonl') as fin:\n",
    "    for line in fin:\n",
    "        hypos.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['string', 'tokens', 'positional_scores', 'knn_scores', 'lm_scores', 'lm_entropy', 'lm_max'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypos[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37130827, 0.55252217, 0.99160496, 0.65741908, 0.9926836 ,\n",
       "       0.99929167, 0.99984313, 0.98193099, 0.99318737, 0.38685434])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.array(hypos[0]['lm_max'][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = '/projects/junxianh/knnlmXS/examples/language_model/wikitext-103/wiki.train.tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesed 0 lines\n",
      "procesed 100000 lines\n",
      "procesed 200000 lines\n",
      "procesed 300000 lines\n",
      "procesed 400000 lines\n",
      "procesed 500000 lines\n",
      "procesed 600000 lines\n",
      "procesed 700000 lines\n",
      "procesed 800000 lines\n",
      "procesed 900000 lines\n",
      "procesed 1000000 lines\n",
      "procesed 1100000 lines\n",
      "procesed 1200000 lines\n",
      "procesed 1300000 lines\n",
      "procesed 1400000 lines\n",
      "procesed 1500000 lines\n",
      "procesed 1600000 lines\n",
      "procesed 1700000 lines\n",
      "procesed 1800000 lines\n"
     ]
    }
   ],
   "source": [
    "freq_cnt = get_ngram_freq(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_cnt[\"you hate me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cnt = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = preprocess_data(hypos, freq_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217646"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217646"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10498046875, 0.9916049558943966, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174116"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.119510650634766e-06, 0.9999994039537299, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174116"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = scaler.transform(x_train)\n",
    "x_val_norm = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.2578125, 0.3713082658051863, 0, 0, 0, 0],\n",
       " [2.84375, 0.5525221705240402, 0, 0, 0, 0],\n",
       " [0.10498046875, 0.9916049558943966, 0, 0, 0, 0],\n",
       " [1.0830078125, 0.6574190806558238, 0, 0, 0, 0],\n",
       " [0.0640869140625, 0.9926836038585435, 0, 0, 0, 0],\n",
       " [0.006256103515625, 0.9992916709664463, 0, 0, 0, 0],\n",
       " [0.0019893646240234375, 0.9998431328798847, 0, 0, 0, 0],\n",
       " [0.1448974609375, 0.9819309852047077, 0, 0, 0, 0],\n",
       " [0.048583984375, 0.9931873743710079, 0, 0, 0, 0],\n",
       " [1.2412109375, 0.38685434308746147, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.52558698,  1.78679802,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 1.50609792, -1.30979425,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.49712464, -0.83988585,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.36261144, -0.42616263,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.99092171,  1.07408044,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.83561193, -1.05754866,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.35653887, -0.82163974,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.48210935,  0.00942679,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.50145036, -0.81683021,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.20147851,  0.44173925,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_norm = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174116, 6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22743281,  0.07513852,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = TokenFeatureDataset(x_train_norm, y_train)\n",
    "val_set = TokenFeatureDataset(x_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(training_set, \n",
    "                                               batch_size=64,\n",
    "                                               shuffle=False,\n",
    "                                               collate_fn=training_set.collater)\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(val_set,\n",
    "                                             batch_size=64,\n",
    "                                             shuffle=False,\n",
    "                                             collate_fn=val_set.collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_check = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7721734 , -0.28048421,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.2578125, 0.3713082658051863, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.2578125,\n",
       " 2.84375,\n",
       " 0.10498046875,\n",
       " 1.0830078125,\n",
       " 0.0640869140625,\n",
       " 0.006256103515625,\n",
       " 0.0019893646240234375,\n",
       " 0.1448974609375,\n",
       " 0.048583984375,\n",
       " 1.2412109375]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypos[0]['lm_entropy'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
       "         28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
       "         42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
       "         56., 57., 58., 59., 60., 61., 62., 63.]),\n",
       " 'feature': tensor([[-1.5256e+00,  1.7868e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.5061e+00, -1.3098e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 4.9712e-01, -8.3989e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-3.6261e-01, -4.2616e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-9.9092e-01,  1.0741e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.3561e-01, -1.0575e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 3.5654e-01, -8.2164e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-4.8211e-01,  9.4268e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 5.0145e-01, -8.1683e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-2.0148e-01,  4.4174e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5846e+00,  1.8223e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 3.2734e-01, -2.2812e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 9.7403e-01, -9.0161e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 2.1055e-01, -7.4441e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 4.7550e-01, -7.8942e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 6.7556e-01, -8.3453e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5792e+00,  1.8188e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.2261e+00,  1.2197e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5654e+00,  1.8119e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.0195e+00, -1.0823e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 6.0310e-01, -6.1010e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.4953e+00, -1.1771e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 5.8064e-02, -4.5678e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 4.2683e-01,  1.0506e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 2.1203e+00, -1.4174e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.4378e-01, -2.3001e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 2.1485e+00, -1.3503e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.9133e-02, -1.7272e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.0101e-01, -6.5951e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-3.1935e-01,  3.4995e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.1437e+00,  1.4939e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 7.5775e-01, -9.5443e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5572e+00,  1.8008e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 7.3828e-01, -8.0781e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.4378e-01,  3.6279e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-3.3558e-01, -1.7259e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.8457e+00, -1.4123e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-8.7467e-01,  9.9418e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.6164e+00, -1.0571e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-8.6818e-01,  1.2680e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5428e+00,  1.7955e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 9.2645e-01, -9.7567e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.3777e-01, -8.5440e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 7.2314e-01, -1.0806e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 2.7002e-01, -1.9936e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.5020e+00,  1.7714e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 9.8052e-01, -7.7350e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 6.0227e-02, -3.9796e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-2.8799e-01,  2.1599e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 4.8090e-01, -7.6392e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.2897e+00,  1.5654e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.8650e-01,  5.4210e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.4141e-03, -1.2905e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.0215e-01, -1.9288e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 5.1443e-01, -7.0466e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.6974e-01,  9.0961e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-3.4938e-02,  1.7986e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.1233e+00, -1.2165e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-1.1320e+00,  1.2017e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.0774e-02,  1.8986e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [-6.0972e-01,  5.4357e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.6294e+00, -1.3395e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 8.0774e-02, -9.2540e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 1.5991e+00, -1.2974e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]]),\n",
       " 'label': tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_dataloader, model):\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    nsamples = 0\n",
    "    truth_list = []\n",
    "    prediction_list = []\n",
    "    for i, sample in enumerate(val_dataloader, 0):\n",
    "        inputs, truth = sample['feature'], sample['label']\n",
    "        truth_list.extend(truth.tolist())\n",
    "#         inputs, labels = sample_check['feature'], sample_check['label']\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, truth)\n",
    "        \n",
    "        # (batch)\n",
    "        _, prediction = torch.max(outputs, dim=1)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        \n",
    "        prediction_list.extend(prediction.tolist())\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        nsamples += inputs.size(0)\n",
    "        \n",
    "    print(f\"val loss: {running_loss/nsamples:.3f}\")\n",
    "    print(f\"val accuracy: {accuracy_score(truth_list, prediction_list):.3f}\")\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(truth_list, \n",
    "                                                              prediction_list, \n",
    "                                                              average='binary', \n",
    "                                                              pos_label=1)\n",
    "    print(f\"val precision: {precision:.3f}, recall: {recall:.3f}\")\n",
    "    \n",
    "    return truth_list, prediction_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 30\n",
    "hidden_units = 128\n",
    "nlayers = 2\n",
    "dropout = 0.\n",
    "lr = 1e-5\n",
    "\n",
    "model = MLPClassifer(training_set.get_nfeature(), \n",
    "                     hidden_units=hidden_units,\n",
    "                     nlayers=nlayers,\n",
    "                     dropout=dropout)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.647\n",
      "val accuracy: 0.659\n",
      "val precision: 0.340, recall: 0.038\n"
     ]
    }
   ],
   "source": [
    "truth_list, prediction_list = validate(val_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43530"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(truth_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43530"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifer(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=128, bias=True)\n",
      "    (1): Dropout(p=0.0, inplace=False)\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "epoch: 0, step: 499,  training loss: 0.618\n",
      "epoch: 0, step: 999,  training loss: 0.606\n",
      "epoch: 0, step: 1499,  training loss: 0.604\n",
      "epoch: 0, step: 1999,  training loss: 0.601\n",
      "epoch: 0, step: 2499,  training loss: 0.601\n",
      "val loss: 0.601\n",
      "val accuracy: 0.669\n",
      "val precision: 0.459, recall: 0.037\n",
      "epoch: 1, step: 499,  training loss: 0.601\n",
      "epoch: 1, step: 999,  training loss: 0.602\n",
      "epoch: 1, step: 1499,  training loss: 0.602\n",
      "epoch: 1, step: 1999,  training loss: 0.601\n",
      "epoch: 1, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.668\n",
      "val precision: 0.456, recall: 0.054\n",
      "epoch: 2, step: 499,  training loss: 0.601\n",
      "epoch: 2, step: 999,  training loss: 0.602\n",
      "epoch: 2, step: 1499,  training loss: 0.602\n",
      "epoch: 2, step: 1999,  training loss: 0.601\n",
      "epoch: 2, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 3, step: 499,  training loss: 0.601\n",
      "epoch: 3, step: 999,  training loss: 0.602\n",
      "epoch: 3, step: 1499,  training loss: 0.602\n",
      "epoch: 3, step: 1999,  training loss: 0.601\n",
      "epoch: 3, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 4, step: 499,  training loss: 0.601\n",
      "epoch: 4, step: 999,  training loss: 0.602\n",
      "epoch: 4, step: 1499,  training loss: 0.602\n",
      "epoch: 4, step: 1999,  training loss: 0.601\n",
      "epoch: 4, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 5, step: 499,  training loss: 0.601\n",
      "epoch: 5, step: 999,  training loss: 0.602\n",
      "epoch: 5, step: 1499,  training loss: 0.602\n",
      "epoch: 5, step: 1999,  training loss: 0.601\n",
      "epoch: 5, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 6, step: 499,  training loss: 0.601\n",
      "epoch: 6, step: 999,  training loss: 0.602\n",
      "epoch: 6, step: 1499,  training loss: 0.602\n",
      "epoch: 6, step: 1999,  training loss: 0.601\n",
      "epoch: 6, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 7, step: 499,  training loss: 0.601\n",
      "epoch: 7, step: 999,  training loss: 0.602\n",
      "epoch: 7, step: 1499,  training loss: 0.602\n",
      "epoch: 7, step: 1999,  training loss: 0.601\n",
      "epoch: 7, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 8, step: 499,  training loss: 0.601\n",
      "epoch: 8, step: 999,  training loss: 0.602\n",
      "epoch: 8, step: 1499,  training loss: 0.602\n",
      "epoch: 8, step: 1999,  training loss: 0.601\n",
      "epoch: 8, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 9, step: 499,  training loss: 0.601\n",
      "epoch: 9, step: 999,  training loss: 0.602\n",
      "epoch: 9, step: 1499,  training loss: 0.602\n",
      "epoch: 9, step: 1999,  training loss: 0.601\n",
      "epoch: 9, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 10, step: 499,  training loss: 0.601\n",
      "epoch: 10, step: 999,  training loss: 0.602\n",
      "epoch: 10, step: 1499,  training loss: 0.602\n",
      "epoch: 10, step: 1999,  training loss: 0.601\n",
      "epoch: 10, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 11, step: 499,  training loss: 0.601\n",
      "epoch: 11, step: 999,  training loss: 0.602\n",
      "epoch: 11, step: 1499,  training loss: 0.602\n",
      "epoch: 11, step: 1999,  training loss: 0.601\n",
      "epoch: 11, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 12, step: 499,  training loss: 0.601\n",
      "epoch: 12, step: 999,  training loss: 0.602\n",
      "epoch: 12, step: 1499,  training loss: 0.602\n",
      "epoch: 12, step: 1999,  training loss: 0.601\n",
      "epoch: 12, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 13, step: 499,  training loss: 0.601\n",
      "epoch: 13, step: 999,  training loss: 0.602\n",
      "epoch: 13, step: 1499,  training loss: 0.602\n",
      "epoch: 13, step: 1999,  training loss: 0.601\n",
      "epoch: 13, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 14, step: 499,  training loss: 0.601\n",
      "epoch: 14, step: 999,  training loss: 0.602\n",
      "epoch: 14, step: 1499,  training loss: 0.602\n",
      "epoch: 14, step: 1999,  training loss: 0.601\n",
      "epoch: 14, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 15, step: 499,  training loss: 0.601\n",
      "epoch: 15, step: 999,  training loss: 0.602\n",
      "epoch: 15, step: 1499,  training loss: 0.602\n",
      "epoch: 15, step: 1999,  training loss: 0.601\n",
      "epoch: 15, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 16, step: 499,  training loss: 0.601\n",
      "epoch: 16, step: 999,  training loss: 0.602\n",
      "epoch: 16, step: 1499,  training loss: 0.602\n",
      "epoch: 16, step: 1999,  training loss: 0.601\n",
      "epoch: 16, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 17, step: 499,  training loss: 0.601\n",
      "epoch: 17, step: 999,  training loss: 0.602\n",
      "epoch: 17, step: 1499,  training loss: 0.602\n",
      "epoch: 17, step: 1999,  training loss: 0.601\n",
      "epoch: 17, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 18, step: 499,  training loss: 0.601\n",
      "epoch: 18, step: 999,  training loss: 0.602\n",
      "epoch: 18, step: 1499,  training loss: 0.602\n",
      "epoch: 18, step: 1999,  training loss: 0.601\n",
      "epoch: 18, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 19, step: 499,  training loss: 0.601\n",
      "epoch: 19, step: 999,  training loss: 0.602\n",
      "epoch: 19, step: 1499,  training loss: 0.602\n",
      "epoch: 19, step: 1999,  training loss: 0.601\n",
      "epoch: 19, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 20, step: 499,  training loss: 0.601\n",
      "epoch: 20, step: 999,  training loss: 0.602\n",
      "epoch: 20, step: 1499,  training loss: 0.602\n",
      "epoch: 20, step: 1999,  training loss: 0.601\n",
      "epoch: 20, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 21, step: 499,  training loss: 0.601\n",
      "epoch: 21, step: 999,  training loss: 0.602\n",
      "epoch: 21, step: 1499,  training loss: 0.602\n",
      "epoch: 21, step: 1999,  training loss: 0.601\n",
      "epoch: 21, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 22, step: 499,  training loss: 0.601\n",
      "epoch: 22, step: 999,  training loss: 0.602\n",
      "epoch: 22, step: 1499,  training loss: 0.602\n",
      "epoch: 22, step: 1999,  training loss: 0.601\n",
      "epoch: 22, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 23, step: 499,  training loss: 0.601\n",
      "epoch: 23, step: 999,  training loss: 0.602\n",
      "epoch: 23, step: 1499,  training loss: 0.602\n",
      "epoch: 23, step: 1999,  training loss: 0.601\n",
      "epoch: 23, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 24, step: 499,  training loss: 0.601\n",
      "epoch: 24, step: 999,  training loss: 0.602\n",
      "epoch: 24, step: 1499,  training loss: 0.602\n",
      "epoch: 24, step: 1999,  training loss: 0.601\n",
      "epoch: 24, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 25, step: 499,  training loss: 0.601\n",
      "epoch: 25, step: 999,  training loss: 0.602\n",
      "epoch: 25, step: 1499,  training loss: 0.602\n",
      "epoch: 25, step: 1999,  training loss: 0.601\n",
      "epoch: 25, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 26, step: 499,  training loss: 0.601\n",
      "epoch: 26, step: 999,  training loss: 0.602\n",
      "epoch: 26, step: 1499,  training loss: 0.602\n",
      "epoch: 26, step: 1999,  training loss: 0.601\n",
      "epoch: 26, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 27, step: 499,  training loss: 0.601\n",
      "epoch: 27, step: 999,  training loss: 0.602\n",
      "epoch: 27, step: 1499,  training loss: 0.602\n",
      "epoch: 27, step: 1999,  training loss: 0.601\n",
      "epoch: 27, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.454, recall: 0.055\n",
      "epoch: 28, step: 499,  training loss: 0.601\n",
      "epoch: 28, step: 999,  training loss: 0.602\n",
      "epoch: 28, step: 1499,  training loss: 0.602\n",
      "epoch: 28, step: 1999,  training loss: 0.601\n",
      "epoch: 28, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.455, recall: 0.055\n",
      "epoch: 29, step: 499,  training loss: 0.601\n",
      "epoch: 29, step: 999,  training loss: 0.602\n",
      "epoch: 29, step: 1499,  training loss: 0.602\n",
      "epoch: 29, step: 1999,  training loss: 0.601\n",
      "epoch: 29, step: 2499,  training loss: 0.601\n",
      "val loss: 0.600\n",
      "val accuracy: 0.667\n",
      "val precision: 0.455, recall: 0.055\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "model.train()\n",
    "for epoch in range(nepochs):\n",
    "    running_loss = 0.\n",
    "    nsamples = 0\n",
    "    for i, sample in enumerate(train_dataloader, 0):\n",
    "        inputs, truth = sample['feature'], sample['label']\n",
    "#         inputs, labels = sample_check['feature'], sample_check['label']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        nsamples += inputs.size(0)\n",
    "        \n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f'epoch: {epoch}, step: {i},  training loss: {running_loss/nsamples:.3f}')\n",
    "            running_loss = 0\n",
    "            nsamples = 0\n",
    "            \n",
    "    validate(val_dataloader, model)\n",
    "    model.train()\n",
    "            \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2765, -0.1965,  0.2563,  0.2765, -0.2565,  0.0878],\n",
       "        [-0.3355,  0.1549,  0.0846,  0.2896, -0.0298, -0.3650],\n",
       "        [ 0.4995,  0.5734, -0.1531,  0.0785,  0.2103, -0.3887],\n",
       "        [-0.0129, -0.1014,  0.0956,  0.0179,  0.0496,  0.0615],\n",
       "        [ 0.1619,  0.2508, -0.0199,  0.3697,  0.0483,  0.1909],\n",
       "        [ 0.0747,  0.1110,  0.0884, -0.2797,  0.2881, -0.1727],\n",
       "        [ 0.1522,  0.0783,  0.2609,  0.0388, -0.2520,  0.1852],\n",
       "        [ 0.0173, -0.0549, -0.2127,  0.0557,  0.2349,  0.3436],\n",
       "        [-0.0514, -0.0788, -0.2656, -0.2521, -0.0080, -0.2199],\n",
       "        [ 0.1538,  0.1476,  0.2338, -0.1833,  0.3058,  0.1342],\n",
       "        [ 0.0370, -0.1428, -0.0290, -0.1752,  0.3829,  0.0872],\n",
       "        [ 0.1598,  0.2272, -0.0186, -0.0433,  0.2779,  0.1212],\n",
       "        [ 0.2339,  0.5931, -0.3093, -0.0167, -0.1937, -0.2987],\n",
       "        [-0.0907, -0.1262,  0.3418,  0.3039, -0.1901,  0.3110],\n",
       "        [-0.4579,  0.1241, -0.3085, -0.2843, -0.3176,  0.3345],\n",
       "        [-0.1248,  0.1931, -0.1710,  0.0483,  0.2633,  0.0588],\n",
       "        [-0.4086,  0.0857, -0.2584, -0.1093, -0.2658,  0.0986],\n",
       "        [-0.2590,  0.0355,  0.2998, -0.0059, -0.1739,  0.3006],\n",
       "        [ 0.0022,  0.3116,  0.2931,  0.0958,  0.2771, -0.1719],\n",
       "        [ 0.1634,  0.4865,  0.2184, -0.0667, -0.3061, -0.1244],\n",
       "        [ 0.1800,  0.2783,  0.3375,  0.2509,  0.3540, -0.2288],\n",
       "        [-0.0588,  0.5458, -0.2185, -0.0669, -0.2237,  0.0995],\n",
       "        [-0.3787, -0.1742, -0.2072,  0.1833,  0.2673,  0.0862],\n",
       "        [-0.3047,  0.3609, -0.2083, -0.2190, -0.2213,  0.0036],\n",
       "        [-0.1165, -0.0964, -0.1277,  0.3754, -0.1737, -0.3704],\n",
       "        [-0.2807,  0.0133, -0.2863,  0.1599, -0.0899,  0.0515],\n",
       "        [-0.3149, -0.1394,  0.0373, -0.0735, -0.2230,  0.0728],\n",
       "        [-0.1867,  0.4632,  0.0334,  0.0377,  0.2120,  0.2989],\n",
       "        [ 0.0799,  0.1339,  0.1178, -0.3191,  0.2094,  0.2433],\n",
       "        [ 0.3775,  0.3646, -0.0310,  0.3829, -0.2465,  0.1185],\n",
       "        [-0.1549, -0.0056,  0.3013,  0.3228,  0.3808, -0.1670],\n",
       "        [ 0.1476,  0.2496,  0.2926,  0.3454,  0.2183, -0.1462],\n",
       "        [-0.2387,  0.2579, -0.1880,  0.2198,  0.0026, -0.0273],\n",
       "        [-0.3025, -0.0785,  0.1828,  0.0982, -0.2899, -0.0909],\n",
       "        [-0.6587, -0.5002, -0.1888, -0.2562,  0.1023,  0.3017],\n",
       "        [ 0.2751,  0.2506, -0.2030,  0.3280, -0.1750, -0.2469],\n",
       "        [-0.1319, -0.1272,  0.0501,  0.1848, -0.2010, -0.1464],\n",
       "        [-0.3127, -0.1362, -0.2023, -0.3299, -0.3400,  0.1838],\n",
       "        [-0.2682, -0.2002, -0.1480, -0.1375,  0.0278, -0.0966],\n",
       "        [-0.2084,  0.2824,  0.0977, -0.0896,  0.0445,  0.2849],\n",
       "        [ 0.0799,  0.0479,  0.2887, -0.2062, -0.1956, -0.2909],\n",
       "        [-0.0256,  0.0420, -0.1803,  0.3219, -0.1208, -0.0263],\n",
       "        [ 0.1224,  0.1828, -0.0504,  0.4029,  0.0925,  0.3036],\n",
       "        [-0.8323, -0.5451,  0.2651,  0.0412,  0.2373,  0.1044],\n",
       "        [ 0.1221,  0.1015, -0.2323, -0.0734,  0.1792,  0.2987],\n",
       "        [ 0.3910,  0.5352,  0.3515,  0.0749, -0.2035, -0.0915],\n",
       "        [-0.1237, -0.1391,  0.3702,  0.2915,  0.3197,  0.1485],\n",
       "        [ 0.0165,  0.0176, -0.3677,  0.1838,  0.2637, -0.3673],\n",
       "        [ 0.1505,  0.1182,  0.3079,  0.3908, -0.1829,  0.3830],\n",
       "        [ 0.1688,  0.1772,  0.3516,  0.3963, -0.0199,  0.2931],\n",
       "        [ 0.0194, -0.1044, -0.2051,  0.3221, -0.1097,  0.1033],\n",
       "        [ 0.2575,  0.4245, -0.0901,  0.1816,  0.3995,  0.1975],\n",
       "        [-0.3795, -0.3093, -0.1085,  0.3129,  0.2906,  0.1224],\n",
       "        [ 0.0447, -0.0008, -0.3008,  0.2587,  0.0618,  0.3495],\n",
       "        [ 0.1157,  0.1444, -0.0327, -0.3251,  0.0326,  0.0863],\n",
       "        [ 0.0259,  0.3356, -0.3616, -0.2434, -0.3638,  0.0873],\n",
       "        [-0.2964, -0.1934,  0.1312,  0.2202,  0.1792,  0.1550],\n",
       "        [ 0.0018,  0.0393, -0.0140, -0.0426, -0.2444,  0.1031],\n",
       "        [ 0.3658,  0.4460, -0.2910, -0.1457, -0.2859,  0.3251],\n",
       "        [ 0.0191, -0.1447, -0.2731, -0.1928, -0.0413, -0.1825],\n",
       "        [-0.1430, -0.1965,  0.0607,  0.0733, -0.0570,  0.2851],\n",
       "        [ 0.1633,  0.2500,  0.1171, -0.1465,  0.0697, -0.1949],\n",
       "        [-0.0586,  0.0096,  0.2322,  0.1257,  0.1681, -0.1177],\n",
       "        [-0.0889, -0.1724, -0.1487, -0.1007, -0.1605,  0.3545]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model[0].weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knnlm",
   "language": "python",
   "name": "knnlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
